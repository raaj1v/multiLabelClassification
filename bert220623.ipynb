{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install pandas beautifulsoup4 scikit-learn transformers torch torchvision -q","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-06-22T12:29:03.616812Z","iopub.execute_input":"2023-06-22T12:29:03.617704Z","iopub.status.idle":"2023-06-22T12:29:20.198149Z","shell.execute_reply.started":"2023-06-22T12:29:03.617666Z","shell.execute_reply":"2023-06-22T12:29:20.196769Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils import shuffle\nfrom transformers import BertTokenizer, BertForSequenceClassification\nimport torch\nfrom torch.utils.data import DataLoader, TensorDataset\nimport re\nfrom bs4 import BeautifulSoup","metadata":{"execution":{"iopub.status.busy":"2023-06-22T12:29:20.202103Z","iopub.execute_input":"2023-06-22T12:29:20.202526Z","iopub.status.idle":"2023-06-22T12:29:20.210466Z","shell.execute_reply.started":"2023-06-22T12:29:20.202477Z","shell.execute_reply":"2023-06-22T12:29:20.209341Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"\n# Set the device to GPU if available, otherwise use CPU\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# Load the CSV file\ncsv_file = '/kaggle/input/tensorflow-classification-multilevel/tenders_08062023.csv'\ndf = pd.read_csv(csv_file)\ndf['ProductName'] = df['ProductName'].apply(lambda x: ', '.join(set([item.strip() for item in x.split(',')])))\n\ndf.dropna(inplace=True)\ndf.reset_index(drop=True, inplace=True)\ndf.head()\n\ndef cleanText(text):\n    text = BeautifulSoup(text, \"lxml\").text  # Remove HTML tags\n    text = re.sub(r'\\|\\|\\|', r' ', text)  # Replace ||| with a single space\n    text = re.sub(r'http\\S+', r'<URL>', text)  # Replace URLs starting with http or https with <URL>\n    text = text.lower()\n    text = text.replace('x', '')  # Remove occurrences of the letter 'x'\n    return text\n\ndef preprocess_text(document):\n    document = re.sub(r'\\W', ' ', str(document))  # Remove special characters\n    document = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', document)  # Remove single characters\n    document = re.sub(r'\\^[a-zA-Z]\\s+', ' ', document)  # Remove single characters from the start\n    document = re.sub(r'\\s+', ' ', document, flags=re.I)  # Replace multiple spaces with single space\n    document = re.sub(r'^b\\s+', '', document)  # Remove prefixed 'b'\n    document = document.lower()  # Convert to lowercase\n    return document\n\n","metadata":{"execution":{"iopub.status.busy":"2023-06-22T12:29:20.212409Z","iopub.execute_input":"2023-06-22T12:29:20.212846Z","iopub.status.idle":"2023-06-22T12:29:25.689325Z","shell.execute_reply.started":"2023-06-22T12:29:20.212787Z","shell.execute_reply":"2023-06-22T12:29:25.688258Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Clean and preprocess the text data\ndf['ProductDetails'] = df['ProductDetails'].apply(cleanText)\ndf['ProductDetails'] = df['ProductDetails'].apply(preprocess_text)\n","metadata":{"execution":{"iopub.status.busy":"2023-06-22T12:29:25.692306Z","iopub.execute_input":"2023-06-22T12:29:25.692708Z","iopub.status.idle":"2023-06-22T12:31:44.446809Z","shell.execute_reply.started":"2023-06-22T12:29:25.692670Z","shell.execute_reply":"2023-06-22T12:31:44.445719Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_28/2112291206.py:14: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n  text = BeautifulSoup(text, \"lxml\").text  # Remove HTML tags\n","output_type":"stream"}]},{"cell_type":"code","source":"df.dropna(inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-06-22T12:31:44.449470Z","iopub.execute_input":"2023-06-22T12:31:44.449858Z","iopub.status.idle":"2023-06-22T12:31:44.801993Z","shell.execute_reply.started":"2023-06-22T12:31:44.449800Z","shell.execute_reply":"2023-06-22T12:31:44.801032Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Shuffle the dataframe\ndf = shuffle(df, random_state=42)\ndf=df.head(10000)\n# Split the data into train and test sets\ntrain_df, test_df = train_test_split(df, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-06-22T12:31:44.803708Z","iopub.execute_input":"2023-06-22T12:31:44.804100Z","iopub.status.idle":"2023-06-22T12:31:44.908485Z","shell.execute_reply.started":"2023-06-22T12:31:44.804066Z","shell.execute_reply":"2023-06-22T12:31:44.907443Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2023-06-22T12:31:44.910264Z","iopub.execute_input":"2023-06-22T12:31:44.910672Z","iopub.status.idle":"2023-06-22T12:31:44.935738Z","shell.execute_reply.started":"2023-06-22T12:31:44.910635Z","shell.execute_reply":"2023-06-22T12:31:44.934601Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"            TCNo     sr_no                                     ProductDetails  \\\n7299    54497115  56740122  gas used at the kobe district court office con...   \n344294  47690401  49939216  rehabilitation of the albu akash water station...   \n57325   49168272  51416132  providing installing 1 no 250 mm dia straight ...   \n355514  54892385  57136406  providing false ceiling for the lab at csb 120...   \n448544  48312600  50561137  supply of various items listed in bhel scanner...   \n...          ...       ...                                                ...   \n447493  59859514  62123393  sale of unusable bit woods on si months rate c...   \n310402  59638074  61900865  renovation of cpwd guest house in cgo towers a...   \n407325  47226338  49475402  fabrication dismantling and erection of pipe l...   \n145654  52518540  54764581  2424 lac ads 2020 21 chalakudy la construction...   \n173442  46913993  49163282  tender notice for construction of mini stadium...   \n\n                                          ProductName  \n7299                               Security Equipment  \n344294                   Pump House, Pipeline Project  \n57325   Drill Machine, Water Supply System, Tube Well  \n355514                                  False Ceiling  \n448544                                       Detector  \n...                                               ...  \n447493                                  Drill Machine  \n310402                     Interior Works, Civil Work  \n407325            Pipeline Project, Dismantaling Work  \n145654                           Auditorium, Building  \n173442                                        Stadium  \n\n[10000 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TCNo</th>\n      <th>sr_no</th>\n      <th>ProductDetails</th>\n      <th>ProductName</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>7299</th>\n      <td>54497115</td>\n      <td>56740122</td>\n      <td>gas used at the kobe district court office con...</td>\n      <td>Security Equipment</td>\n    </tr>\n    <tr>\n      <th>344294</th>\n      <td>47690401</td>\n      <td>49939216</td>\n      <td>rehabilitation of the albu akash water station...</td>\n      <td>Pump House, Pipeline Project</td>\n    </tr>\n    <tr>\n      <th>57325</th>\n      <td>49168272</td>\n      <td>51416132</td>\n      <td>providing installing 1 no 250 mm dia straight ...</td>\n      <td>Drill Machine, Water Supply System, Tube Well</td>\n    </tr>\n    <tr>\n      <th>355514</th>\n      <td>54892385</td>\n      <td>57136406</td>\n      <td>providing false ceiling for the lab at csb 120...</td>\n      <td>False Ceiling</td>\n    </tr>\n    <tr>\n      <th>448544</th>\n      <td>48312600</td>\n      <td>50561137</td>\n      <td>supply of various items listed in bhel scanner...</td>\n      <td>Detector</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>447493</th>\n      <td>59859514</td>\n      <td>62123393</td>\n      <td>sale of unusable bit woods on si months rate c...</td>\n      <td>Drill Machine</td>\n    </tr>\n    <tr>\n      <th>310402</th>\n      <td>59638074</td>\n      <td>61900865</td>\n      <td>renovation of cpwd guest house in cgo towers a...</td>\n      <td>Interior Works, Civil Work</td>\n    </tr>\n    <tr>\n      <th>407325</th>\n      <td>47226338</td>\n      <td>49475402</td>\n      <td>fabrication dismantling and erection of pipe l...</td>\n      <td>Pipeline Project, Dismantaling Work</td>\n    </tr>\n    <tr>\n      <th>145654</th>\n      <td>52518540</td>\n      <td>54764581</td>\n      <td>2424 lac ads 2020 21 chalakudy la construction...</td>\n      <td>Auditorium, Building</td>\n    </tr>\n    <tr>\n      <th>173442</th>\n      <td>46913993</td>\n      <td>49163282</td>\n      <td>tender notice for construction of mini stadium...</td>\n      <td>Stadium</td>\n    </tr>\n  </tbody>\n</table>\n<p>10000 rows × 4 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df = df[['ProductDetails', 'ProductName']]","metadata":{"execution":{"iopub.status.busy":"2023-06-22T12:31:44.937345Z","iopub.execute_input":"2023-06-22T12:31:44.938418Z","iopub.status.idle":"2023-06-22T12:31:44.949733Z","shell.execute_reply.started":"2023-06-22T12:31:44.938364Z","shell.execute_reply":"2023-06-22T12:31:44.948556Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"X = df['ProductDetails'].values\nY = df['ProductName'].values","metadata":{"execution":{"iopub.status.busy":"2023-06-22T12:31:44.953041Z","iopub.execute_input":"2023-06-22T12:31:44.953562Z","iopub.status.idle":"2023-06-22T12:31:44.961188Z","shell.execute_reply.started":"2023-06-22T12:31:44.953520Z","shell.execute_reply":"2023-06-22T12:31:44.959877Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# import torch\n# from transformers import BertTokenizer, BertForSequenceClassification\n\nimport torch\nfrom transformers import BertTokenizer, BertModel\n\n# Load pre-trained tokenizer and model\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\nmodel = BertModel.from_pretrained('bert-base-uncased')","metadata":{"execution":{"iopub.status.busy":"2023-06-22T12:31:45.336282Z","iopub.execute_input":"2023-06-22T12:31:45.337099Z","iopub.status.idle":"2023-06-22T12:31:56.768917Z","shell.execute_reply.started":"2023-06-22T12:31:45.337059Z","shell.execute_reply":"2023-06-22T12:31:56.767790Z"},"trusted":true},"execution_count":42,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)solve/main/vocab.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"82fab255847941929c88c575f7e97742"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ed6dc657b3c6456d9d7c6343fc6f8b9c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"172326a53aa54e6bbb9c06ec1dfd3c1f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"20a5ddfd90614d15b0b30f68261228c6"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight']\n- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"}]},{"cell_type":"code","source":"custom_labels = [\n    \"Lime\", \"Chlorinator\", \"Barrage\", \"Chimney\", \"Boring Machine\", \"Bullet Proof Jacket\",\n    \"Auditorium\", \"Fountain\", \"Jetty\", \"Helmet\", \"Runway\", \"Dredging Work\", \"Land Levelling\",\n    \"Earth Filling\", \"Stadium\", \"Bus Stand\", \"Chlorination Plant\", \"Drilling Work\", \"Tunnel Work\",\n    \"Sump\", \"Temple\", \"Channel Work\", \"Ballast\", \"Trenching Work\", \"Statue\", \"Manhole Chamber\",\n    \"Foundation\", \"Reverse Osmosis Plant\", \"Barrack\", \"Interior Works\", \"False Ceiling\",\n    \"Pump House\", \"Land Development\", \"Effluent Treatment Plant\", \"Swimming Pool\",\n    \"Sewage Treatment Plant\", \"Dam Gate\", \"Dismantling Work\", \"Lining Work\", \"Demolition\",\n    \"Shelter\", \"Drill Machine\", \"Platform\", \"Earth Work\", \"Parking Work\", \"Dam Work\",\n    \"Arms/Ammunation Equipment\", \"Detector\", \"Seal\", \"Lake Development\", \"Culvert Work\",\n    \"Excavation Work\", \"Desilting\", \"Bore Well\", \"Lift Irrigation\", \"Cable Laying\",\n    \"Fire Detection System\", \"Well Work\", \"Protection Kit\", \"Fire Alarm System\",\n    \"Soil Investigation\", \"Landscape\", \"Tube Well\", \"Sports Ground\", \"Environmental Work\",\n    \"C C T V System\", \"Reservoir\", \"R C C Work\", \"Sewerage Line\", \"Toilet\", \"Fencing Work\",\n    \"Water Purification System\", \"Tank\", \"Water Treatment Plant\", \"Canal Work\", \"Painting Work\",\n    \"Hardware And Accessories\", \"Yard Work\", \"Roof Work\", \"Bridge\", \"Fire Fighting System\",\n    \"Water Supply System\", \"Plumbing And Sanitary Work\", \"Security Equipment\",\n    \"Surveillance System\", \"Shed Construction\", \"Building Material\", \"Wall\", \"Laying Pipe\",\n    \"Flooring\", \"Water Supply\", \"Drainage\", \"Pipeline Project\", \"Building\", \"Road\", \"Civil Work\"\n]\n","metadata":{"execution":{"iopub.status.busy":"2023-06-22T12:31:56.770472Z","iopub.execute_input":"2023-06-22T12:31:56.770989Z","iopub.status.idle":"2023-06-22T12:31:56.783374Z","shell.execute_reply.started":"2023-06-22T12:31:56.770950Z","shell.execute_reply":"2023-06-22T12:31:56.782347Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import TensorDataset, DataLoader\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import classification_report\nfrom transformers import BertTokenizer, BertForSequenceClassification\n\n# Set device\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2023-06-22T12:31:56.785138Z","iopub.execute_input":"2023-06-22T12:31:56.785685Z","iopub.status.idle":"2023-06-22T12:31:56.805355Z","shell.execute_reply.started":"2023-06-22T12:31:56.785645Z","shell.execute_reply":"2023-06-22T12:31:56.804133Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import TensorDataset, DataLoader\nfrom sklearn.preprocessing import MultiLabelBinarizer\nfrom sklearn.metrics import classification_report\nfrom transformers import BertTokenizer, BertForSequenceClassification","metadata":{"execution":{"iopub.status.busy":"2023-06-22T12:31:56.807543Z","iopub.execute_input":"2023-06-22T12:31:56.807966Z","iopub.status.idle":"2023-06-22T12:31:56.818255Z","shell.execute_reply.started":"2023-06-22T12:31:56.807929Z","shell.execute_reply":"2023-06-22T12:31:56.817179Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"# Set device\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","metadata":{"execution":{"iopub.status.busy":"2023-06-22T12:31:56.819619Z","iopub.execute_input":"2023-06-22T12:31:56.821112Z","iopub.status.idle":"2023-06-22T12:31:56.834443Z","shell.execute_reply.started":"2023-06-22T12:31:56.821073Z","shell.execute_reply":"2023-06-22T12:31:56.833249Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"# Load the pre-trained tokenizer\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n\n","metadata":{"execution":{"iopub.status.busy":"2023-06-22T12:31:56.836246Z","iopub.execute_input":"2023-06-22T12:31:56.836984Z","iopub.status.idle":"2023-06-22T12:31:56.927283Z","shell.execute_reply.started":"2023-06-22T12:31:56.836945Z","shell.execute_reply":"2023-06-22T12:31:56.925569Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"train_df.shape","metadata":{"execution":{"iopub.status.busy":"2023-06-22T12:31:56.930030Z","iopub.execute_input":"2023-06-22T12:31:56.932242Z","iopub.status.idle":"2023-06-22T12:31:56.941402Z","shell.execute_reply.started":"2023-06-22T12:31:56.932206Z","shell.execute_reply":"2023-06-22T12:31:56.939129Z"},"trusted":true},"execution_count":48,"outputs":[{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"(8000, 4)"},"metadata":{}}]},{"cell_type":"code","source":"test_df.shape","metadata":{"execution":{"iopub.status.busy":"2023-06-22T12:31:56.944519Z","iopub.execute_input":"2023-06-22T12:31:56.945268Z","iopub.status.idle":"2023-06-22T12:31:56.975679Z","shell.execute_reply.started":"2023-06-22T12:31:56.945228Z","shell.execute_reply":"2023-06-22T12:31:56.973749Z"},"trusted":true},"execution_count":49,"outputs":[{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"(2000, 4)"},"metadata":{}}]},{"cell_type":"code","source":"# Tokenize the input data\ntrain_encodings = tokenizer.batch_encode_plus(\n    train_df['ProductDetails'].tolist(),\n    truncation=True,\n    padding=True,\n    return_tensors='pt'\n)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-06-22T12:31:56.978808Z","iopub.execute_input":"2023-06-22T12:31:56.980114Z","iopub.status.idle":"2023-06-22T12:32:16.221720Z","shell.execute_reply.started":"2023-06-22T12:31:56.980072Z","shell.execute_reply":"2023-06-22T12:32:16.220669Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"test_encodings = tokenizer.batch_encode_plus(\n    test_df['ProductDetails'].tolist(),\n    truncation=True,\n    padding=True,\n    return_tensors='pt'\n)","metadata":{"execution":{"iopub.status.busy":"2023-06-22T12:32:16.223775Z","iopub.execute_input":"2023-06-22T12:32:16.224241Z","iopub.status.idle":"2023-06-22T12:32:21.176941Z","shell.execute_reply.started":"2023-06-22T12:32:16.224207Z","shell.execute_reply":"2023-06-22T12:32:21.175823Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"# Prepare the input tensors\ntrain_inputs = train_encodings['input_ids'].to(device)\ntrain_masks = train_encodings['attention_mask'].to(device)\ntrain_labels = train_df['ProductName']\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-06-22T12:32:21.179229Z","iopub.execute_input":"2023-06-22T12:32:21.179625Z","iopub.status.idle":"2023-06-22T12:32:21.202612Z","shell.execute_reply.started":"2023-06-22T12:32:21.179589Z","shell.execute_reply":"2023-06-22T12:32:21.201534Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"test_inputs = test_encodings['input_ids'].to(device)\ntest_masks = test_encodings['attention_mask'].to(device)\ntest_labels = test_df['ProductName']","metadata":{"execution":{"iopub.status.busy":"2023-06-22T12:32:21.204274Z","iopub.execute_input":"2023-06-22T12:32:21.204708Z","iopub.status.idle":"2023-06-22T12:32:21.214598Z","shell.execute_reply.started":"2023-06-22T12:32:21.204652Z","shell.execute_reply":"2023-06-22T12:32:21.213413Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"\n# Convert the labels to binary format\nlabel_encoder = MultiLabelBinarizer()\ntrain_labels_encoded = label_encoder.fit_transform(train_labels)\ntest_labels_encoded = label_encoder.transform(test_labels)\n\n# Create PyTorch datasets\ntrain_dataset = TensorDataset(train_inputs, train_masks, torch.tensor(train_labels_encoded).to(device))\ntest_dataset = TensorDataset(test_inputs, test_masks, torch.tensor(test_labels_encoded).to(device))\n\n# Define model configuration\nnum_labels = len(label_encoder.classes_)\nmodel = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=num_labels)\nmodel.to(device)\n\n# Create data loaders\nbatch_size = 16\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n\n# Define optimizer and loss function\nlearning_rate = 1e-5\noptimizer = optim.Adam(model.parameters(), lr=learning_rate)\nloss_fn = nn.BCEWithLogitsLoss()\n","metadata":{"execution":{"iopub.status.busy":"2023-06-22T12:32:21.216054Z","iopub.execute_input":"2023-06-22T12:32:21.217328Z","iopub.status.idle":"2023-06-22T12:32:22.749905Z","shell.execute_reply.started":"2023-06-22T12:32:21.217288Z","shell.execute_reply":"2023-06-22T12:32:22.748829Z"},"trusted":true},"execution_count":54,"outputs":[{"name":"stderr","text":"Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight']\n- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"train_labels_encoded","metadata":{"execution":{"iopub.status.busy":"2023-06-22T13:19:01.991913Z","iopub.execute_input":"2023-06-22T13:19:01.992303Z","iopub.status.idle":"2023-06-22T13:19:02.002108Z","shell.execute_reply.started":"2023-06-22T13:19:01.992272Z","shell.execute_reply":"2023-06-22T13:19:02.000905Z"},"trusted":true},"execution_count":95,"outputs":[{"execution_count":95,"output_type":"execute_result","data":{"text/plain":"array([[1, 1, 0, ..., 0, 1, 0],\n       [1, 1, 0, ..., 0, 0, 0],\n       [1, 1, 0, ..., 0, 0, 0],\n       ...,\n       [1, 0, 0, ..., 0, 0, 0],\n       [1, 0, 0, ..., 0, 0, 0],\n       [1, 0, 0, ..., 1, 0, 0]])"},"metadata":{}}]},{"cell_type":"code","source":"num_labels","metadata":{"execution":{"iopub.status.busy":"2023-06-22T13:18:09.172019Z","iopub.execute_input":"2023-06-22T13:18:09.172389Z","iopub.status.idle":"2023-06-22T13:18:09.178977Z","shell.execute_reply.started":"2023-06-22T13:18:09.172358Z","shell.execute_reply":"2023-06-22T13:18:09.177971Z"},"trusted":true},"execution_count":94,"outputs":[{"execution_count":94,"output_type":"execute_result","data":{"text/plain":"49"},"metadata":{}}]},{"cell_type":"code","source":"import numpy as np\n\n# Save train_labels_encoded to a CSV file\nnp.savetxt('train_labels.csv', train_labels_encoded, delimiter=',', fmt='%d')\n","metadata":{"execution":{"iopub.status.busy":"2023-06-22T13:23:40.206731Z","iopub.execute_input":"2023-06-22T13:23:40.207214Z","iopub.status.idle":"2023-06-22T13:23:40.337194Z","shell.execute_reply.started":"2023-06-22T13:23:40.207179Z","shell.execute_reply":"2023-06-22T13:23:40.336066Z"},"trusted":true},"execution_count":96,"outputs":[]},{"cell_type":"code","source":"num_epochs = 1\nprint_interval = 100  \n\nmodel.train()\n\nfor epoch in range(num_epochs):\n    total_loss = 0\n    \n    for batch_idx, batch in enumerate(train_loader):\n        input_ids, attention_mask, labels = batch\n        input_ids = input_ids.to(device)\n        attention_mask = attention_mask.to(device)\n        labels = labels.float().to(device)\n        \n        optimizer.zero_grad()\n        \n        outputs = model(input_ids, attention_mask=attention_mask)\n        logits = outputs.logits\n        \n        loss = loss_fn(logits, labels)\n        loss.backward()\n        \n        optimizer.step()\n        \n        total_loss += loss.item()\n        \n        # Print batch loss\n        if (batch_idx + 1) % print_interval == 0:\n            print(f\"Epoch [{epoch+1}/{num_epochs}], Batch [{batch_idx+1}/{len(train_loader)}], Loss: {loss.item():.4f}\")\n    \n    # Print epoch loss\n    epoch_loss = total_loss / len(train_loader)\n    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}\")\n\nprint(\"Training finished.\")\n","metadata":{"execution":{"iopub.status.busy":"2023-06-22T12:32:22.762449Z","iopub.execute_input":"2023-06-22T12:32:22.762856Z","iopub.status.idle":"2023-06-22T12:39:16.422134Z","shell.execute_reply.started":"2023-06-22T12:32:22.762802Z","shell.execute_reply":"2023-06-22T12:39:16.420993Z"},"trusted":true},"execution_count":56,"outputs":[{"name":"stdout","text":"Epoch [1/1], Batch [100/500], Loss: 0.4999\nEpoch [1/1], Batch [200/500], Loss: 0.4242\nEpoch [1/1], Batch [300/500], Loss: 0.4183\nEpoch [1/1], Batch [400/500], Loss: 0.4151\nEpoch [1/1], Batch [500/500], Loss: 0.3969\nEpoch [1/1], Loss: 0.4704\nTraining finished.\n","output_type":"stream"}]},{"cell_type":"code","source":"# save_path = \"/kaggle/working/model\"\n\n# # Save the model\n# model.save_pretrained(save_path)\n        \n# # Save the tokenizer as well\n# tokenizer.save_pretrained(save_path)\n\n# print(\"Model saved successfully.\")\n","metadata":{"execution":{"iopub.status.busy":"2023-06-22T09:34:25.284747Z","iopub.execute_input":"2023-06-22T09:34:25.285103Z","iopub.status.idle":"2023-06-22T09:34:25.888517Z","shell.execute_reply.started":"2023-06-22T09:34:25.285076Z","shell.execute_reply":"2023-06-22T09:34:25.887587Z"},"trusted":true},"execution_count":60,"outputs":[{"name":"stdout","text":"Model saved successfully.\n","output_type":"stream"}]},{"cell_type":"code","source":"eval_dataset=test_df","metadata":{"execution":{"iopub.status.busy":"2023-06-22T12:39:16.423854Z","iopub.execute_input":"2023-06-22T12:39:16.424524Z","iopub.status.idle":"2023-06-22T12:39:16.430069Z","shell.execute_reply.started":"2023-06-22T12:39:16.424486Z","shell.execute_reply":"2023-06-22T12:39:16.428382Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"eval_loader = DataLoader(eval_dataset, batch_size=batch_size, shuffle=False)\n","metadata":{"execution":{"iopub.status.busy":"2023-06-22T12:39:16.431840Z","iopub.execute_input":"2023-06-22T12:39:16.432267Z","iopub.status.idle":"2023-06-22T12:39:16.445848Z","shell.execute_reply.started":"2023-06-22T12:39:16.432223Z","shell.execute_reply":"2023-06-22T12:39:16.444379Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\nmodel.eval()\n\npredictions = []\ntrue_labels = []\n\nwith torch.no_grad():\n    for batch in test_loader:\n        input_ids, attention_mask, labels = batch\n        input_ids = input_ids.to(device)\n        attention_mask = attention_mask.to(device)\n        labels = labels.float().to(device)\n        \n        outputs = model(input_ids, attention_mask=attention_mask)\n        logits = outputs.logits\n        \n        # Apply sigmoid activation and convert logits to probabilities\n        probabilities = torch.sigmoid(logits)\n        \n        # Round probabilities to get binary predictions (0 or 1)\n        predicted_labels = torch.round(probabilities).squeeze().cpu().tolist()\n        \n        # Collect predictions and true labels for computing metrics\n        predictions.extend(predicted_labels)\n        true_labels.extend(labels.cpu().tolist())\n\n# Calculate classification metrics\nclassification_metrics = classification_report(true_labels, predictions)\n\n# Print classification metrics\nprint(classification_metrics)\n","metadata":{"execution":{"iopub.status.busy":"2023-06-22T12:39:16.450081Z","iopub.execute_input":"2023-06-22T12:39:16.450424Z","iopub.status.idle":"2023-06-22T12:39:51.037308Z","shell.execute_reply.started":"2023-06-22T12:39:16.450396Z","shell.execute_reply":"2023-06-22T12:39:51.036265Z"},"trusted":true},"execution_count":59,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.90      1.00      0.95      1798\n           1       0.79      0.71      0.75      1282\n           2       0.00      0.00      0.00         4\n           3       0.00      0.00      0.00       121\n           4       0.00      0.00      0.00       408\n           5       0.90      0.04      0.08       657\n           6       0.00      0.00      0.00       627\n           7       0.00      0.00      0.00       227\n           8       0.00      0.00      0.00       279\n           9       0.00      0.00      0.00       148\n          10       0.00      0.00      0.00        78\n          11       0.00      0.00      0.00       123\n          12       0.00      0.00      0.00        17\n          13       0.00      0.00      0.00        40\n          14       0.00      0.00      0.00       343\n          15       0.00      0.00      0.00       291\n          16       0.00      0.00      0.00        70\n          17       0.91      0.19      0.31       630\n          18       0.00      0.00      0.00       358\n          19       0.85      0.12      0.22       756\n          20       0.00      0.00      0.00       455\n          21       0.00      0.00      0.00        29\n          22       0.79      0.71      0.75      1183\n          23       0.00      0.00      0.00        56\n          24       0.77      1.00      0.87      1538\n          25       0.00      0.00      0.00       218\n          26       0.85      0.05      0.09       739\n          27       1.00      0.00      0.01       671\n          28       0.78      1.00      0.88      1565\n          29       0.00      0.00      0.00       218\n          30       0.73      0.64      0.68      1104\n          31       0.00      0.00      0.00       584\n          32       0.79      1.00      0.88      1570\n          33       0.00      0.00      0.00       168\n          34       0.78      0.42      0.54      1047\n          35       0.79      1.00      0.89      1588\n          36       0.79      0.38      0.51      1015\n          37       0.84      1.00      0.91      1686\n          38       0.72      1.00      0.84      1450\n          39       0.00      0.00      0.00       523\n          40       0.00      0.00      0.00        34\n          41       0.87      1.00      0.93      1732\n          42       0.76      0.16      0.26       780\n          43       0.72      1.00      0.84      1446\n          44       0.84      0.20      0.33       900\n          45       0.96      0.04      0.08       634\n          46       0.00      0.00      0.00       205\n          47       0.00      0.00      0.00        72\n          48       1.00      0.05      0.09       399\n\n   micro avg       0.80      0.57      0.67     31866\n   macro avg       0.39      0.26      0.26     31866\nweighted avg       0.67      0.57      0.55     31866\n samples avg       0.78      0.58      0.65     31866\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}]},{"cell_type":"code","source":"# model = torch.load(\"/kaggle/working/model\")\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndecoded_labels = label_encoder.inverse_transform(train_labels_encoded)\n\n# Print the decoded labels\n# print(decoded_labels)\n","metadata":{"execution":{"iopub.status.busy":"2023-06-22T13:10:34.364022Z","iopub.execute_input":"2023-06-22T13:10:34.364438Z","iopub.status.idle":"2023-06-22T13:10:34.411192Z","shell.execute_reply.started":"2023-06-22T13:10:34.364406Z","shell.execute_reply":"2023-06-22T13:10:34.410118Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\n# Load the label encoder used during training\nlabel_encoder = MultiLabelBinarizer()\nlabel_encoder.fit(train_labels)\n\n# Convert the predictions to a NumPy array\npredictions = np.asarray(predictions)\n\n# Reshape the predictions to a 2-dimensional array\npredictions = predictions.reshape(1, -1)\n\n# Inverse transform the predictions to obtain the original labels\npredicted_labels = label_encoder.inverse_transform(predictions)\n\nprint(predicted_labels)\n","metadata":{"execution":{"iopub.status.busy":"2023-06-22T13:13:55.613522Z","iopub.execute_input":"2023-06-22T13:13:55.613967Z","iopub.status.idle":"2023-06-22T13:13:55.630292Z","shell.execute_reply.started":"2023-06-22T13:13:55.613934Z","shell.execute_reply":"2023-06-22T13:13:55.629153Z"},"trusted":true},"execution_count":83,"outputs":[{"name":"stdout","text":"[(' ', 'e', 'i', 'n', 'o', 'r')]\n","output_type":"stream"}]},{"cell_type":"code","source":"# Convert the predictions to a NumPy array\npredictions = np.asarray(predictions)\n\nprint(predictions)\n","metadata":{"execution":{"iopub.status.busy":"2023-06-22T13:14:22.114338Z","iopub.execute_input":"2023-06-22T13:14:22.114850Z","iopub.status.idle":"2023-06-22T13:14:22.123247Z","shell.execute_reply.started":"2023-06-22T13:14:22.114785Z","shell.execute_reply":"2023-06-22T13:14:22.122017Z"},"trusted":true},"execution_count":84,"outputs":[{"name":"stdout","text":"[[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0\n  0 1 1 0 0 1 0 0 0 0 0 0 0]]\n","output_type":"stream"}]},{"cell_type":"code","source":"# Convert the binary predictions to boolean values\npredicted_labels_binary = predictions.astype(bool)\n\n# Inverse transform the binary labels to obtain the original labels\npredicted_labels = label_encoder.inverse_transform(predicted_labels_binary)\n\n# Print the predicted labels\nprint(predicted_labels)\n","metadata":{"execution":{"iopub.status.busy":"2023-06-22T13:15:27.635345Z","iopub.execute_input":"2023-06-22T13:15:27.635804Z","iopub.status.idle":"2023-06-22T13:15:27.647000Z","shell.execute_reply.started":"2023-06-22T13:15:27.635767Z","shell.execute_reply":"2023-06-22T13:15:27.645599Z"},"trusted":true},"execution_count":86,"outputs":[{"name":"stdout","text":"[(' ', 'e', 'i', 'n', 'o', 'r')]\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport numpy as np\n\ntext = input(\"Enter your sentence: \")\n\n\nencoding = tokenizer(text, return_tensors=\"pt\")\ninput_ids = encoding[\"input_ids\"].to(device)\nattention_mask = encoding[\"attention_mask\"].to(device)\n\nwith torch.no_grad():\n    outputs = model(input_ids, attention_mask=attention_mask)\n    logits = outputs.logits\n\n# Apply sigmoid activation\nsigmoid = torch.nn.Sigmoid()\nprobs = sigmoid(logits.squeeze().cpu())\n\n# Apply threshold for binary classification\nthreshold = 0.7\npredictions = (probs >= threshold).int()\n\n# Convert predictions to a list of binary labels\npredicted_labels = predictions.squeeze().tolist()\n\nprint(predicted_labels)","metadata":{"execution":{"iopub.status.busy":"2023-06-22T13:15:42.979579Z","iopub.execute_input":"2023-06-22T13:15:42.979994Z","iopub.status.idle":"2023-06-22T13:15:48.905974Z","shell.execute_reply.started":"2023-06-22T13:15:42.979961Z","shell.execute_reply":"2023-06-22T13:15:48.904801Z"},"trusted":true},"execution_count":87,"outputs":[{"output_type":"stream","name":"stdin","text":"Enter your sentence:  CONSTRUCTION OF ROAD\n"},{"name":"stdout","text":"[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n","output_type":"stream"}]},{"cell_type":"code","source":"a=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\nlen(a)","metadata":{"execution":{"iopub.status.busy":"2023-06-22T12:54:23.831050Z","iopub.execute_input":"2023-06-22T12:54:23.831459Z","iopub.status.idle":"2023-06-22T12:54:23.842040Z","shell.execute_reply.started":"2023-06-22T12:54:23.831426Z","shell.execute_reply":"2023-06-22T12:54:23.840990Z"},"trusted":true},"execution_count":68,"outputs":[{"execution_count":68,"output_type":"execute_result","data":{"text/plain":"49"},"metadata":{}}]},{"cell_type":"code","source":"# Apply sigmoid activation and convert logits to probabilities\nprobabilities = torch.sigmoid(logits)\n\n# Round probabilities to get binary predictions (0 or 1)\npredicted_labels = torch.round(probabilities).squeeze().cpu().tolist()\n\n# Get the predicted classes based on the indices\npredicted_classes = [label_encoder.classes_[i] for i, label in enumerate(predicted_labels) if label == 1]\n\n# Print the predicted labels\nprint(f\"Predicted Labels: {predicted_classes}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-06-22T12:59:48.244361Z","iopub.execute_input":"2023-06-22T12:59:48.244752Z","iopub.status.idle":"2023-06-22T12:59:48.254087Z","shell.execute_reply.started":"2023-06-22T12:59:48.244721Z","shell.execute_reply":"2023-06-22T12:59:48.252990Z"},"trusted":true},"execution_count":69,"outputs":[{"name":"stdout","text":"Predicted Labels: [' ', ',', 'W', 'a', 'e', 'g', 'i', 'l', 'n', 'o', 'r', 't']\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport numpy as np\n\n# Load your trained model\nmodel = torch.load(\"/kaggle/working/model.pth\")\n\n\n# Define the preprocess_sentence function\ndef preprocess_sentence(sentence):\n    max_length = 128  # Define the maximum length for your input sequences\n    \n    # Tokenize the sentence\n    tokens = tokenizer.tokenize(sentence)\n    \n    # Add special tokens and convert tokens to input tensors\n    input_ids = tokenizer.encode(tokens, add_special_tokens=True)\n    \n    # Pad or truncate the input to the defined maximum length\n    input_ids = input_ids[:max_length] + [tokenizer.pad_token_id] * (max_length - len(input_ids))\n    \n    # Create attention mask\n    attention_mask = [1] * len(input_ids)\n    \n    # Convert input to tensors and move to device\n    input_ids = torch.tensor(input_ids).unsqueeze(0).to(device)\n    attention_mask = torch.tensor(attention_mask).unsqueeze(0).to(device)\n    \n    return input_ids, attention_mask\n\n# Example sentence\nsentence = input(\"Enter your sentence: \")\n\n# Preprocess the sentence\ninput_ids, attention_mask = preprocess_sentence(sentence)\n\n# Pass the preprocessed input through the model\nwith torch.no_grad():\n    outputs = model(input_ids, attention_mask=attention_mask)\n    logits = outputs.logits\n    \n    # Apply sigmoid activation and convert logits to probabilities\n    probabilities = torch.sigmoid(logits)\n    \n    # Round probabilities to get binary predictions (0 or 1)\n    predicted_labels = torch.round(probabilities).squeeze().cpu().tolist()\n\n# Get the predicted classes based on the indices\npredicted_classes = [label_encoder.classes_[i] for i, label in enumerate(predicted_labels) if label == 1]\n\n# Print the predicted labels\nprint(f\"Predicted Labels: {predicted_classes}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-06-22T11:23:28.256397Z","iopub.execute_input":"2023-06-22T11:23:28.256758Z","iopub.status.idle":"2023-06-22T11:23:28.346933Z","shell.execute_reply.started":"2023-06-22T11:23:28.256730Z","shell.execute_reply":"2023-06-22T11:23:28.345529Z"},"trusted":true},"execution_count":151,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[151], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Load your trained model\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/kaggle/working/model.pth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Define the preprocess_sentence function\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess_sentence\u001b[39m(sentence):\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/serialization.py:791\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    789\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 791\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m    792\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    793\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    794\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    795\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    796\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/serialization.py:271\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 271\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    273\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/serialization.py:252\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 252\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/working/model.pth'"],"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/kaggle/working/model.pth'","output_type":"error"}]},{"cell_type":"code","source":"import torch\nimport numpy as np\n\n# Define the preprocess_sentence function\ndef preprocess_sentence(sentence):\n    max_length = 128  # Define the maximum length for your input sequences\n    \n    # Tokenize the sentence\n    tokens = tokenizer.tokenize(sentence)\n    \n    # Add special tokens and convert tokens to input tensors\n    input_ids = tokenizer.encode(tokens, add_special_tokens=True)\n    \n    # Pad or truncate the input to the defined maximum length\n    input_ids = input_ids[:max_length] + [tokenizer.pad_token_id] * (max_length - len(input_ids))\n    \n    # Create attention mask\n    attention_mask = [1] * len(input_ids)\n    \n    # Convert input to tensors and move to device\n    input_ids = torch.tensor(input_ids).unsqueeze(0).to(device)\n    attention_mask = torch.tensor(attention_mask).unsqueeze(0).to(device)\n    \n    return input_ids, attention_mask\n\n# Example sentence\nsentence = input(\"Enter your sentence: \")\n\n# Preprocess the sentence\ninput_ids, attention_mask = preprocess_sentence(sentence)\n\n# Pass the preprocessed input through the model\nwith torch.no_grad():\n    outputs = model(input_ids, attention_mask=attention_mask)\n    logits = outputs.logits\n    \n    # Apply sigmoid activation and convert logits to probabilities\n    probabilities = torch.sigmoid(logits)\n    \n    # Round probabilities to get binary predictions (0 or 1)\n    predicted_labels = torch.round(probabilities).squeeze().cpu().tolist()\n\n# Get the predicted classes based on the indices\npredicted_classes = [label_encoder.classes_[i] for i, label in enumerate(predicted_labels) if label == 1]\n\n# Print the predicted labels\nprint(f\"Predicted Labels: {predicted_classes}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-06-22T11:20:25.579847Z","iopub.execute_input":"2023-06-22T11:20:25.580197Z","iopub.status.idle":"2023-06-22T11:20:29.198742Z","shell.execute_reply.started":"2023-06-22T11:20:25.580169Z","shell.execute_reply":"2023-06-22T11:20:29.197701Z"},"trusted":true},"execution_count":147,"outputs":[{"output_type":"stream","name":"stdin","text":"Enter your sentence:  road\n"},{"name":"stdout","text":"Predicted Labels: ['Chlorinator', 'Barrage', 'Auditorium', 'Helmet', 'Land Levelling', 'Bus Stand', 'Chlorination Plant', 'Tunnel Work', 'Temple', 'Channel Work', 'Ballast', 'Statue', 'Reverse Osmosis Plant', 'Barrack', 'Interior Works', 'False Ceiling', 'Sewage Treatment Plant', 'Dismantling Work', 'Lining Work', 'Drill Machine', 'Earth Work', 'Parking Work', 'Lake Development', 'Bore Well', 'Well Work', 'Protection Kit', 'Landscape', 'Tube Well', 'Environmental Work', 'C C T V System', 'R C C Work', 'Water Purification System', 'Water Treatment Plant', 'Canal Work', 'Painting Work', 'Hardware And Accessories', 'Roof Work', 'Bridge', 'Security Equipment', 'Shed Construction', 'Building Material', 'Wall', 'Flooring', 'Building', 'Road']\n","output_type":"stream"}]},{"cell_type":"code","source":"df.head(10)\n","metadata":{"execution":{"iopub.status.busy":"2023-06-22T11:18:17.720301Z","iopub.execute_input":"2023-06-22T11:18:17.720675Z","iopub.status.idle":"2023-06-22T11:18:17.731745Z","shell.execute_reply.started":"2023-06-22T11:18:17.720645Z","shell.execute_reply":"2023-06-22T11:18:17.730707Z"},"trusted":true},"execution_count":143,"outputs":[{"execution_count":143,"output_type":"execute_result","data":{"text/plain":"                                           ProductDetails  \\\n7299    gas used at the kobe district court office con...   \n344294  rehabilitation of the albu akash water station...   \n57325   providing installing 1 no 250 mm dia straight ...   \n355514  providing false ceiling for the lab at csb 120...   \n448544  supply of various items listed in bhel scanner...   \n311404  reno and upgrading works ofqtrno a3including c...   \n433491  lpr fhis 55 2022 construction hydraulic concre...   \n285017  providing and installation of 1000lph ro unit ...   \n254967  the acquisition of collection composed of orig...   \n362378  interior furnishing electrical data work for b...   \n\n                                              ProductName  \n7299                                   Security Equipment  \n344294                       Pump House, Pipeline Project  \n57325       Drill Machine, Water Supply System, Tube Well  \n355514                                      False Ceiling  \n448544                                           Detector  \n311404  Civil Work, False Ceiling, Flooring, Pipeline ...  \n433491                            Lining Work, R C C Work  \n285017  Water Purification System, Shed Construction, ...  \n254967                                             Statue  \n362378                                     Interior Works  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ProductDetails</th>\n      <th>ProductName</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>7299</th>\n      <td>gas used at the kobe district court office con...</td>\n      <td>Security Equipment</td>\n    </tr>\n    <tr>\n      <th>344294</th>\n      <td>rehabilitation of the albu akash water station...</td>\n      <td>Pump House, Pipeline Project</td>\n    </tr>\n    <tr>\n      <th>57325</th>\n      <td>providing installing 1 no 250 mm dia straight ...</td>\n      <td>Drill Machine, Water Supply System, Tube Well</td>\n    </tr>\n    <tr>\n      <th>355514</th>\n      <td>providing false ceiling for the lab at csb 120...</td>\n      <td>False Ceiling</td>\n    </tr>\n    <tr>\n      <th>448544</th>\n      <td>supply of various items listed in bhel scanner...</td>\n      <td>Detector</td>\n    </tr>\n    <tr>\n      <th>311404</th>\n      <td>reno and upgrading works ofqtrno a3including c...</td>\n      <td>Civil Work, False Ceiling, Flooring, Pipeline ...</td>\n    </tr>\n    <tr>\n      <th>433491</th>\n      <td>lpr fhis 55 2022 construction hydraulic concre...</td>\n      <td>Lining Work, R C C Work</td>\n    </tr>\n    <tr>\n      <th>285017</th>\n      <td>providing and installation of 1000lph ro unit ...</td>\n      <td>Water Purification System, Shed Construction, ...</td>\n    </tr>\n    <tr>\n      <th>254967</th>\n      <td>the acquisition of collection composed of orig...</td>\n      <td>Statue</td>\n    </tr>\n    <tr>\n      <th>362378</th>\n      <td>interior furnishing electrical data work for b...</td>\n      <td>Interior Works</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import torch\n# from transformers import BertTokenizer, BertForSequenceClassification\n# from sklearn.preprocessing import MultiLabelBinarizer\n\n# # Load pre-trained tokenizer\n# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n\n# # Set the device to GPU if available, otherwise use CPU\n# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# # Define label encoder\n# label_encoder = MultiLabelBinarizer()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Define label encoder\n# label_encoder = MultiLabelBinarizer()\n# label_encoder.classes_ = [\n#     \"Lime\", \"Chlorinator\", \"Barrage\", \"Chimney\", \"Boring Machine\", \"Bullet Proof Jacket\",\n#     \"Auditorium\", \"Fountain\", \"Jetty\", \"Helmet\", \"Runway\", \"Dredging Work\", \"Land Levelling\",\n#     \"Earth Filling\", \"Stadium\", \"Bus Stand\", \"Chlorination Plant\", \"Drilling Work\", \"Tunnel Work\",\n#     \"Sump\", \"Temple\", \"Channel Work\", \"Ballast\", \"Trenching Work\", \"Statue\", \"Manhole Chamber\",\n#     \"Foundation\", \"Reverse Osmosis Plant\", \"Barrack\", \"Interior Works\", \"False Ceiling\",\n#     \"Pump House\", \"Land Development\", \"Effluent Treatment Plant\", \"Swimming Pool\",\n#     \"Sewage Treatment Plant\", \"Dam Gate\", \"Dismantling Work\", \"Lining Work\", \"Demolition\",\n#     \"Shelter\", \"Drill Machine\", \"Platform\", \"Earth Work\", \"Parking Work\", \"Dam Work\",\n#     \"Arms/Ammunation Equipment\", \"Detector\", \"Seal\", \"Lake Development\", \"Culvert Work\",\n#     \"Excavation Work\", \"Desilting\", \"Bore Well\", \"Lift Irrigation\", \"Cable Laying\",\n#     \"Fire Detection System\", \"Well Work\", \"Protection Kit\", \"Fire Alarm System\",\n#     \"Soil Investigation\", \"Landscape\", \"Tube Well\", \"Sports Ground\", \"Environmental Work\",\n#     \"C C T V System\", \"Reservoir\", \"R C C Work\", \"Sewerage Line\", \"Toilet\", \"Fencing Work\",\n#     \"Water Purification System\", \"Tank\", \"Water Treatment Plant\", \"Canal Work\", \"Painting Work\",\n#     \"Hardware And Accessories\", \"Yard Work\", \"Roof Work\", \"Bridge\", \"Fire Fighting System\",\n#     \"Water Supply System\", \"Plumbing And Sanitary Work\", \"Security Equipment\",\n#     \"Surveillance System\", \"Shed Construction\", \"Building Material\", \"Wall\", \"Laying Pipe\",\n#     \"Flooring\", \"Water Supply\", \"Drainage\", \"Pipeline Project\", \"Building\", \"Road\", \"Civil Work\"\n# ]","metadata":{"execution":{"iopub.status.busy":"2023-06-22T10:35:10.321696Z","iopub.execute_input":"2023-06-22T10:35:10.322007Z","iopub.status.idle":"2023-06-22T10:35:10.330744Z","shell.execute_reply.started":"2023-06-22T10:35:10.321981Z","shell.execute_reply":"2023-06-22T10:35:10.329728Z"},"trusted":true},"execution_count":102,"outputs":[]},{"cell_type":"code","source":"# import torch\n# import numpy as np\n# from sklearn.preprocessing import MultiLabelBinarizer","metadata":{"execution":{"iopub.status.busy":"2023-06-22T10:49:37.121117Z","iopub.execute_input":"2023-06-22T10:49:37.121468Z","iopub.status.idle":"2023-06-22T10:49:37.126736Z","shell.execute_reply.started":"2023-06-22T10:49:37.121438Z","shell.execute_reply":"2023-06-22T10:49:37.125670Z"},"trusted":true},"execution_count":114,"outputs":[]},{"cell_type":"code","source":"# Example sentence\nsentence = input(\"Enter your sentence: \")\n\n# Preprocess the sentence\ncleaned_sentence = cleanText(sentence)\npreprocessed_sentence = preprocess_text(cleaned_sentence)\n\n# Tokenize the preprocessed sentence\nencoding = tokenizer.encode_plus(\n    preprocessed_sentence,\n    truncation=True,\n    padding=True,\n    return_tensors='pt'\n)\n\n# Extract input tensors\ninput_ids = encoding['input_ids']\nattention_mask = encoding['attention_mask']\n\n# Move tensors to device\ninput_ids = input_ids.to(device)\nattention_mask = attention_mask.to(device)\n\n# Define the threshold value\nthreshold = 0.6\n\n# Perform inference\nmodel.eval()\nwith torch.no_grad():\n    outputs = model(input_ids, attention_mask=attention_mask)\n    logits = outputs.logits\n    probabilities = torch.sigmoid(logits)\n    predicted_labels = (probabilities > threshold).squeeze().cpu().tolist()\n\n# Convert predicted labels to integers\npredicted_labels = [int(label) for label in predicted_labels]\n\n# Filter out labels below the threshold\nrelevant_labels = [label_encoder.classes_[idx] for idx, label in enumerate(predicted_labels) if label == 1]\n\n# Print the predicted labels\nprint(relevant_labels)","metadata":{"execution":{"iopub.status.busy":"2023-06-22T11:20:45.510956Z","iopub.execute_input":"2023-06-22T11:20:45.511309Z","iopub.status.idle":"2023-06-22T11:20:57.647719Z","shell.execute_reply.started":"2023-06-22T11:20:45.511279Z","shell.execute_reply":"2023-06-22T11:20:57.646689Z"},"trusted":true},"execution_count":148,"outputs":[{"output_type":"stream","name":"stdin","text":"Enter your sentence:  National Highway Authority Of India for Independent Engineer Services for Supervision of (i) Construction of 4/6 Lane Northern Ayodhya Bypass total length of 35.40 kms of Part-1 north of NH-27, from km 0+000 to km 30+400 (Starting near existing km 112+540, ending at km 139+928 of NH-27) and Part- 2 south of NH-27 from km 0+000 to km 5+000 (ii) Construction of 4/6 Lane Southern Ayodhya Bypass from km 5+000 to km 37+172 (Starting near km 112+540, ending at km 153+281 of NH-27) of total length of 32.172 kms on HAM basis under NHDP Phase-VII in the State of Uttar Pradesh. at Not Classified,Uttar Pradesh,India\n"},{"name":"stdout","text":"['Chlorinator', 'Landscape', 'Tube Well', 'Environmental Work', 'Hardware And Accessories', 'Roof Work', 'Bridge', 'Security Equipment']\n","output_type":"stream"}]},{"cell_type":"code","source":"# Preprocess the input sentence\ninput_sentence = input(\"Enter your sentence: \")\ncleaned_sentence = cleanText(input_sentence)\npreprocessed_sentence = preprocess_text(cleaned_sentence)\n\n# Tokenize the preprocessed sentence\ninput_encoding = tokenizer.encode_plus(\n    preprocessed_sentence,\n    truncation=True,\n    padding=True,\n    return_tensors='pt'\n)\n\n# Prepare the input tensors\ninput_ids = input_encoding['input_ids'].to(device)\nattention_mask = input_encoding['attention_mask'].to(device)\n\n# Switch model to evaluation mode\nmodel.eval()\n\n# Pass the input tensors through the model to obtain logits\nwith torch.no_grad():\n    outputs = model(input_ids, attention_mask=attention_mask)\n    logits = outputs.logits\n\n# Apply threshold-based predictions\nthreshold = 0.5\nprobabilities = torch.sigmoid(logits)\npredictions = (probabilities > threshold).long()\n\n# Convert predictions back to labels\n\npredicted_labels = [label_encoder.inverse_transform(pred) for pred in predictions.cpu().numpy()]\n\n# Print the predicted labels\nprint(\"Predicted Labels:\", predicted_labels)\n","metadata":{"execution":{"iopub.status.busy":"2023-06-22T11:07:25.732322Z","iopub.execute_input":"2023-06-22T11:07:25.732694Z","iopub.status.idle":"2023-06-22T11:07:28.323117Z","shell.execute_reply.started":"2023-06-22T11:07:25.732661Z","shell.execute_reply":"2023-06-22T11:07:28.321870Z"},"trusted":true},"execution_count":138,"outputs":[{"output_type":"stream","name":"stdin","text":"Enter your sentence:  ROAD\n"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[138], line 33\u001b[0m\n\u001b[1;32m     29\u001b[0m predictions \u001b[38;5;241m=\u001b[39m (probabilities \u001b[38;5;241m>\u001b[39m threshold)\u001b[38;5;241m.\u001b[39mlong()\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Convert predictions back to labels\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m predicted_labels \u001b[38;5;241m=\u001b[39m [label_encoder\u001b[38;5;241m.\u001b[39minverse_transform(pred) \u001b[38;5;28;01mfor\u001b[39;00m pred \u001b[38;5;129;01min\u001b[39;00m predictions\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()]\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Print the predicted labels\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicted Labels:\u001b[39m\u001b[38;5;124m\"\u001b[39m, predicted_labels)\n","Cell \u001b[0;32mIn[138], line 33\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     29\u001b[0m predictions \u001b[38;5;241m=\u001b[39m (probabilities \u001b[38;5;241m>\u001b[39m threshold)\u001b[38;5;241m.\u001b[39mlong()\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Convert predictions back to labels\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m predicted_labels \u001b[38;5;241m=\u001b[39m [\u001b[43mlabel_encoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minverse_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m pred \u001b[38;5;129;01min\u001b[39;00m predictions\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()]\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Print the predicted labels\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicted Labels:\u001b[39m\u001b[38;5;124m\"\u001b[39m, predicted_labels)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:920\u001b[0m, in \u001b[0;36mMultiLabelBinarizer.inverse_transform\u001b[0;34m(self, yt)\u001b[0m\n\u001b[1;32m    905\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Transform the given indicator matrix into label sets.\u001b[39;00m\n\u001b[1;32m    906\u001b[0m \n\u001b[1;32m    907\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    916\u001b[0m \u001b[38;5;124;03m    `classes_[j]` for each `yt[i, j] == 1`.\u001b[39;00m\n\u001b[1;32m    917\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    918\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 920\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43myt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_):\n\u001b[1;32m    921\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    922\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected indicator for \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m classes, but got \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    923\u001b[0m             \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_), yt\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    924\u001b[0m         )\n\u001b[1;32m    925\u001b[0m     )\n\u001b[1;32m    927\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sp\u001b[38;5;241m.\u001b[39missparse(yt):\n","\u001b[0;31mIndexError\u001b[0m: tuple index out of range"],"ename":"IndexError","evalue":"tuple index out of range","output_type":"error"}]},{"cell_type":"code","source":"# print(\"Predicted labels:\", predicted_labels)\n# print(\"Classes:\", label_encoder.classes_)\n","metadata":{"execution":{"iopub.status.busy":"2023-06-22T11:06:56.126894Z","iopub.execute_input":"2023-06-22T11:06:56.127577Z","iopub.status.idle":"2023-06-22T11:06:56.131935Z","shell.execute_reply.started":"2023-06-22T11:06:56.127524Z","shell.execute_reply":"2023-06-22T11:06:56.130926Z"},"trusted":true},"execution_count":137,"outputs":[]},{"cell_type":"code","source":"# import torch\n\n# # User input sentence\n# user_sentence = input(\"Enter your sentence: \")\n\n# # Tokenize the user input\n# user_encoding = tokenizer.encode_plus(\n#     user_sentence,\n#     truncation=True,\n#     padding=True,\n#     return_tensors='pt'\n# )\n\n# user_input_ids = user_encoding['input_ids'].to(device)\n# user_attention_mask = user_encoding['attention_mask'].to(device)\n\n# # Make predictions for the user input\n# model.eval()\n# with torch.no_grad():\n#     user_outputs = model(user_input_ids, attention_mask=user_attention_mask)\n#     user_logits = user_outputs.logits\n#     user_predictions = (user_logits.sigmoid() > 0.5).cpu().numpy().tolist()\n\n# # Convert predictions to custom labels for the user input\n# user_custom_labels = [custom_labels[i] for i, pred in enumerate(user_predictions[0]) if pred]\n\n# # Print the custom labels for the user input\n# print(user_custom_labels)\n","metadata":{"execution":{"iopub.status.busy":"2023-06-22T07:18:06.389714Z","iopub.execute_input":"2023-06-22T07:18:06.390083Z","iopub.status.idle":"2023-06-22T07:18:08.247314Z","shell.execute_reply.started":"2023-06-22T07:18:06.390053Z","shell.execute_reply":"2023-06-22T07:18:08.246205Z"},"trusted":true},"execution_count":77,"outputs":[{"output_type":"stream","name":"stdin","text":"Enter your sentence:  National Highway Authority Of India for RFP for Construction of Four Lane Elevated Corridor and at-grade improvements from Design Ch:0+000 to Design Ch: 19+870 of Danapur – Bihta Section with providing connectivity to the existing RoB near Danapur station (0.231 km), 1.35 Km ramps & at-grade improvements to Four lane section on Danapur side and Upgradation of existing Two lane carriageway to Four Lane carriageway from Design Ch:19+870 to Design Ch:23+500 of Bihta - Koilwar section (Total Length 25.081 Kms) in the state of Bihar on EPC Mode at Not Classified,Bihar,India\n"},{"name":"stdout","text":"['Lime', 'Chlorinator', 'Bullet Proof Jacket', 'Ballast', 'Statue', 'Reverse Osmosis Plant', 'Barrack', 'False Ceiling', 'Land Development', 'Swimming Pool', 'Sewage Treatment Plant', 'Dismantling Work', 'Lining Work', 'Drill Machine', 'Earth Work', 'Parking Work', 'Dam Work']\n","output_type":"stream"}]},{"cell_type":"code","source":"# import torch\n\n# # User input sentence\n# user_sentence = input(\"Enter your sentence: \")\n\n# # Tokenize the user input\n# user_encoding = tokenizer.encode_plus(\n#     user_sentence,\n#     truncation=True,\n#     padding=True,\n#     return_tensors='pt'\n# )\n\n# user_input_ids = user_encoding['input_ids'].to(device)\n# user_attention_mask = user_encoding['attention_mask'].to(device)\n\n# # Make predictions for the user input\n# model.eval()\n# with torch.no_grad():\n#     user_outputs = model(user_input_ids, attention_mask=user_attention_mask)\n#     user_probabilities = torch.sigmoid(user_outputs.logits)\n#     user_predictions = (user_probabilities > 0.5).cpu().numpy().tolist()\n\n# # Convert predictions to custom labels for the user input\n# user_custom_labels = [custom_labels[i] for i, pred in enumerate(user_predictions[0]) if pred]\n\n# # Print the custom labels for the user input\n# print(user_custom_labels)\n","metadata":{"execution":{"iopub.status.busy":"2023-06-22T11:01:47.351832Z","iopub.execute_input":"2023-06-22T11:01:47.352179Z","iopub.status.idle":"2023-06-22T11:01:47.357294Z","shell.execute_reply.started":"2023-06-22T11:01:47.352151Z","shell.execute_reply":"2023-06-22T11:01:47.356058Z"},"trusted":true},"execution_count":128,"outputs":[]},{"cell_type":"code","source":"# import torch\n# from sklearn.metrics.pairwise import cosine_similarity\n\n# num_epochs = 5\n# print_interval = 100\n# train_embeddings = []\n\n# model.train()\n\n# for epoch in range(num_epochs):\n#     total_loss = 0\n    \n#     for batch_idx, batch in enumerate(train_loader):\n#         input_ids, attention_mask, labels = batch\n#         input_ids = input_ids.to(device)\n#         attention_mask = attention_mask.to(device)\n#         labels = labels.float().to(device)\n        \n#         optimizer.zero_grad()\n        \n#         # Pass the attention mask to individual layers of the model\n#         outputs = model.bert(input_ids, attention_mask=attention_mask)\n#         pooled_output = outputs.pooler_output\n        \n#         # Compute logits from pooled output\n#         logits = model.classifier(pooled_output)\n        \n#         loss = loss_fn(logits, labels)\n#         loss.backward()\n        \n#         optimizer.step()\n        \n#         total_loss += loss.item()\n        \n#         # Save the embeddings for each batch\n#         with torch.no_grad():\n#             batch_embeddings = model.bert.embeddings(input_ids, attention_mask)\n#             train_embeddings.extend(batch_embeddings.tolist())\n        \n#         # Print batch loss\n#         if (batch_idx + 1) % print_interval == 0:\n#             print(f\"Epoch [{epoch+1}/{num_epochs}], Batch [{batch_idx+1}/{len(train_loader)}], Loss: {loss.item():.4f}\")\n    \n#     # Print epoch loss\n#     epoch_loss = total_loss / len(train_loader)\n#     print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}\")\n\n# print(\"Training finished.\")\n","metadata":{"execution":{"iopub.status.busy":"2023-06-22T08:42:55.050214Z","iopub.execute_input":"2023-06-22T08:42:55.050603Z","iopub.status.idle":"2023-06-22T08:42:55.370948Z","shell.execute_reply.started":"2023-06-22T08:42:55.050553Z","shell.execute_reply":"2023-06-22T08:42:55.368369Z"},"trusted":true},"execution_count":27,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","Cell \u001b[0;32mIn[27], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Pass the attention mask to individual layers of the model\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbert\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mpooler_output\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Compute logits from pooled output\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:1013\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[1;32m   1007\u001b[0m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[1;32m   1008\u001b[0m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[1;32m   1009\u001b[0m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[1;32m   1011\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m-> 1013\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1014\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1015\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1017\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1018\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1019\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1020\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(\n\u001b[1;32m   1021\u001b[0m     embedding_output,\n\u001b[1;32m   1022\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mextended_attention_mask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[1;32m   1031\u001b[0m )\n\u001b[1;32m   1032\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:230\u001b[0m, in \u001b[0;36mBertEmbeddings.forward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[1;32m    227\u001b[0m         token_type_ids \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(input_shape, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition_ids\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 230\u001b[0m     inputs_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mword_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    231\u001b[0m token_type_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken_type_embeddings(token_type_ids)\n\u001b[1;32m    233\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m inputs_embeds \u001b[38;5;241m+\u001b[39m token_type_embeddings\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/sparse.py:162\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 162\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:2210\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2204\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2205\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2206\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2207\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2208\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2209\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2210\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 15.90 GiB total capacity; 14.96 GiB already allocated; 35.75 MiB free; 14.99 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"],"ename":"OutOfMemoryError","evalue":"CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 15.90 GiB total capacity; 14.96 GiB already allocated; 35.75 MiB free; 14.99 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","output_type":"error"}]},{"cell_type":"code","source":"import torch\nfrom sklearn.metrics.pairwise import cosine_similarity\n\n# User input sentence\nuser_sentence = input(\"Enter your sentence: \")\n\n# Tokenize the user input\nuser_encoding = tokenizer.encode_plus(\n    user_sentence,\n    truncation=True,\n    padding=True,\n    return_tensors='pt'\n)\n\nuser_input_ids = user_encoding['input_ids'].to(device)\nuser_attention_mask = user_encoding['attention_mask'].to(device)\n\n# Get the embeddings for the user input\nwith torch.no_grad():\n    user_embeddings = model.bert.embeddings(user_input_ids, user_attention_mask)\n\n# Calculate cosine similarity with each training data embedding\nsimilarities = torch.cosine_similarity(user_embeddings, train_embeddings)\n\n# Find the indices of the most similar training data\nmost_similar_indices = similarities.argmax(dim=1).tolist()\n\n# Get the corresponding custom labels\nuser_custom_labels = [train_df['ProductDetails'].iloc[idx] for idx in most_similar_indices]\n\n# Print the custom labels for the user input\nprint(user_custom_labels)\n","metadata":{"execution":{"iopub.status.busy":"2023-06-22T07:23:10.768307Z","iopub.execute_input":"2023-06-22T07:23:10.769043Z","iopub.status.idle":"2023-06-22T07:23:16.026415Z","shell.execute_reply.started":"2023-06-22T07:23:10.769007Z","shell.execute_reply":"2023-06-22T07:23:16.025140Z"},"trusted":true},"execution_count":79,"outputs":[{"output_type":"stream","name":"stdin","text":"Enter your sentence:  construction of road\n"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[79], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m     user_embeddings \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mbert\u001b[38;5;241m.\u001b[39membeddings(user_input_ids, user_attention_mask)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Calculate cosine similarity with each training data embedding\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m similarities \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcosine_similarity(user_embeddings, \u001b[43mtrain_embeddings\u001b[49m)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Find the indices of the most similar training data\u001b[39;00m\n\u001b[1;32m     26\u001b[0m most_similar_indices \u001b[38;5;241m=\u001b[39m similarities\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mtolist()\n","\u001b[0;31mNameError\u001b[0m: name 'train_embeddings' is not defined"],"ename":"NameError","evalue":"name 'train_embeddings' is not defined","output_type":"error"}]},{"cell_type":"code","source":"!pip install sentence_transformers\n","metadata":{"execution":{"iopub.status.busy":"2023-06-22T07:30:01.813378Z","iopub.execute_input":"2023-06-22T07:30:01.813799Z","iopub.status.idle":"2023-06-22T07:30:15.636520Z","shell.execute_reply.started":"2023-06-22T07:30:01.813765Z","shell.execute_reply":"2023-06-22T07:30:15.635312Z"},"trusted":true},"execution_count":83,"outputs":[{"name":"stdout","text":"Collecting sentence_transformers\n  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (4.30.1)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (4.64.1)\nRequirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (2.0.0)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (0.15.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (1.23.5)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (1.10.1)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (3.2.4)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (0.1.99)\nRequirement already satisfied: huggingface-hub>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (0.15.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (3.12.0)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2023.6.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2.28.2)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (5.4.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.5.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (21.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers) (3.1.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2023.5.5)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.13.3)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.3.1)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from nltk->sentence_transformers) (1.16.0)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (1.2.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (3.1.0)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->sentence_transformers) (9.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence_transformers) (3.0.9)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.6.0->sentence_transformers) (2.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2023.5.7)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.6.0->sentence_transformers) (1.3.0)\nBuilding wheels for collected packages: sentence_transformers\n  Building wheel for sentence_transformers (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for sentence_transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125938 sha256=5e335d4786b686023c516e2280a74f36bca43c9d269848984716441effee4ed8\n  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\nSuccessfully built sentence_transformers\nInstalling collected packages: sentence_transformers\nSuccessfully installed sentence_transformers-2.2.2\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"from sentence_transformers import SentenceTransformer, util\n\n# Load pre-trained model\nmodel = SentenceTransformer('distilbert-base-nli-stsb-mean-tokens')\n\n# Example sentences\nsentence1 = \"construction of road.\"\nsentence2 = \"road\"\n\n# Encode sentences into embeddings\nembeddings1 = model.encode([sentence1], convert_to_tensor=True)\nembeddings2 = model.encode([sentence2], convert_to_tensor=True)\n\n# Calculate cosine similarity\nsimilarity = util.pytorch_cos_sim(embeddings1, embeddings2)[0][0].item()\n\nprint(f\"Semantic textual similarity: {similarity:.4f}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-06-22T07:30:15.640779Z","iopub.execute_input":"2023-06-22T07:30:15.641123Z","iopub.status.idle":"2023-06-22T07:30:53.878124Z","shell.execute_reply.started":"2023-06-22T07:30:15.641091Z","shell.execute_reply":"2023-06-22T07:30:53.877304Z"},"trusted":true},"execution_count":84,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)7e0d5/.gitattributes:   0%|          | 0.00/345 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c87a02e926914cb79bda7ce29b89368b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5e77a692cbc940a6a37530eb770be1e3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)0e5ca7e0d5/README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"94e8eb725d584a259cc3eaf9f6e5cf41"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)5ca7e0d5/config.json:   0%|          | 0.00/555 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6fa4b54f774a46699dc97108d4e9053b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)ce_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"410a0abbc4a14fdda672cf37623a2319"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading pytorch_model.bin:   0%|          | 0.00/265M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"998479f8baf648b4b89c88da61f2a5a2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)nce_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f32d5eb284d4d8da7f63a797e6a4f42"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c200643f43144fbe8480b68910856a31"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)7e0d5/tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a7196993c924898abe6051292eaf2bb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/505 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f2fd240e65540919878b16c45035e00"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)0e5ca7e0d5/vocab.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb822e7f34da4696a914ed519bd56bea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)ca7e0d5/modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6bfb733d2bf34ce0b6c4a1df15c8cbff"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b0fcd7dc40374ea4863510be5815c2c5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4ed6b8d1bfeb433f9209802d12c55c99"}},"metadata":{}},{"name":"stdout","text":"Semantic textual similarity: 0.7728\n","output_type":"stream"}]},{"cell_type":"code","source":"from sentence_transformers import SentenceTransformer, util\n\n# Load pre-trained model\nmodel = SentenceTransformer('distilbert-base-nli-stsb-mean-tokens')\n\n# # Load custom_labels dataset and extract the text column\n# custom_labels = [...]  # Your custom_labels dataset\n\n# Encode the text column to obtain label embeddings\nlabel_embeddings = model.encode(custom_labels, convert_to_tensor=True)\n\n# User input sentence\nuser_sentence = input(\"Enter your sentence: \")\n\n# Encode the user input sentence\nuser_embedding = model.encode([user_sentence], convert_to_tensor=True)\n\n# Calculate cosine similarity between user embedding and label embeddings\nsimilarities = util.pytorch_cos_sim(user_embedding, label_embeddings)\n\n# Sort labels based on similarity scores\nsorted_indices = similarities.argsort(descending=True).squeeze().tolist()\nsorted_labels = [custom_labels[i] for i in sorted_indices]\nsimilarity_scores = similarities.squeeze().tolist()\n\n# Print labels with higher similarity and their corresponding similarity scores\nfor label, score in zip(sorted_labels, similarity_scores):\n    print(f\"Label: {label}\\nSimilarity Score: {score:.4f}\\n\")\n","metadata":{"execution":{"iopub.status.busy":"2023-06-22T07:41:13.909096Z","iopub.execute_input":"2023-06-22T07:41:13.909901Z"},"trusted":true},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"57465805b4ca4b7da3254c5f20fe6849"}},"metadata":{}}]},{"cell_type":"raw","source":"","metadata":{}},{"cell_type":"code","source":"from sentence_transformers import SentenceTransformer, util\n\n# Load pre-trained model\nmodel = SentenceTransformer('distilbert-base-nli-stsb-mean-tokens')\n\n# # Load custom_labels dataset and extract the text column\n# custom_labels = [...]  # Your custom_labels dataset\n\n# Encode the text column to obtain label embeddings\nlabel_embeddings = model.encode(custom_labels, convert_to_tensor=True)\n\n# User input sentence\nuser_sentence = input(\"Enter your sentence: \")\n\n# Encode the user input sentence\nuser_embedding = model.encode([user_sentence], convert_to_tensor=True)\n\n# Calculate cosine similarity between user embedding and label embeddings\nsimilarities = util.pytorch_cos_sim(user_embedding, label_embeddings)\n\n# Define threshold for similarity scores\nthreshold = 0.8\n\n# Sort labels based on similarity scores\nsorted_indices = similarities.argsort(descending=True).squeeze().tolist()\nsorted_labels = [custom_labels[i] for i in sorted_indices]\nsimilarity_scores = similarities.squeeze().tolist()\n\n# Print labels with similarity scores above the threshold\nfor label, score in zip(sorted_labels, similarity_scores):\n    if score > threshold:\n        print(f\"Label: {label}\\nSimilarity Score: {score:.4f}\\n\")\n","metadata":{"execution":{"iopub.status.busy":"2023-06-22T08:33:13.145514Z","iopub.execute_input":"2023-06-22T08:33:13.145836Z","iopub.status.idle":"2023-06-22T08:33:13.703943Z","shell.execute_reply.started":"2023-06-22T08:33:13.145807Z","shell.execute_reply":"2023-06-22T08:33:13.698794Z"},"trusted":true},"execution_count":1,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer, util\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Load pre-trained model\u001b[39;00m\n\u001b[1;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m SentenceTransformer(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdistilbert-base-nli-stsb-mean-tokens\u001b[39m\u001b[38;5;124m'\u001b[39m)\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sentence_transformers'"],"ename":"ModuleNotFoundError","evalue":"No module named 'sentence_transformers'","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}